{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4475020",
   "metadata": {},
   "source": [
    "# Sequential vs Sequential2D Comparison\n",
    "\n",
    "This notebook compares PyTorch's built-in Sequential container with our custom Sequential2D container, demonstrating:\n",
    "\n",
    "1. **Functional Equivalence**: Cases where both produce identical results\n",
    "2. **Architectural Differences**: Unique capabilities of Sequential2D\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the differences between linear sequential architectures and 2D block architectures\n",
    "- Learn when Sequential2D provides advantages over standard Sequential\n",
    "- Analyze performance trade-offs in different scenarios\n",
    "- Gain insights into advanced neural network architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba40f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from iterativennsimple.Sequential2D import Sequential2D, Identity\n",
    "from iterativennsimple.Sequential1D import Sequential1D\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")  # Force CPU for this example\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828cc19",
   "metadata": {},
   "source": [
    "## Part 1: Functional Equivalence\n",
    "\n",
    "Let's start by showing how Sequential2D can replicate the behavior of PyTorch's Sequential container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c35e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical number of parameters:118282\n",
      "Network architectures created successfully!\n",
      "Sequential parameters: 118282\n",
      "Sequential2D parameters: 118282\n"
     ]
    }
   ],
   "source": [
    "def create_equivalent_networks():\n",
    "    \"\"\"\n",
    "    Create functionally equivalent networks using Sequential and Sequential2D\n",
    "    \"\"\"\n",
    "    # Network dimensions\n",
    "    input_size = 784  # MNIST-like input\n",
    "    hidden_size = 128\n",
    "    output_size = 10\n",
    "    \n",
    "    f1 = nn.Linear(input_size, hidden_size)\n",
    "    f2 = nn.Linear(hidden_size, hidden_size)\n",
    "    f3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # PyTorch Sequential Network\n",
    "    sequential_net = nn.Sequential(\n",
    "        f1,\n",
    "        nn.ReLU(),\n",
    "        f2,\n",
    "        nn.ReLU(),\n",
    "        f3\n",
    "    )\n",
    "    \n",
    "    in_features_list = [input_size, hidden_size, hidden_size, output_size]\n",
    "    out_features_list = [input_size, hidden_size, hidden_size, output_size]\n",
    "    \n",
    "    # Create blocks matrix for linear chain\n",
    "    I = Identity(in_features=input_size, out_features=input_size)\n",
    "    # Note, the ReLU activations are included in the Sequential1D blocks, but can go different places\n",
    "    # in the Sequential2D structure.\n",
    "    F1 = Sequential1D(nn.Sequential(f1),            in_features=input_size,  out_features=hidden_size)\n",
    "    F2 = Sequential1D(nn.Sequential(nn.ReLU(), f2), in_features=hidden_size, out_features=hidden_size)\n",
    "    F3 = Sequential1D(nn.Sequential(nn.ReLU(), f3), in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    # NOTE: Mind the transposed structure of the blocks in the matrix!\n",
    "    blocks = [[I,    F1,   None, None],\n",
    "              [None, None, F2,   None],\n",
    "              [None, None, None, F3],\n",
    "              [None, None, None, None]]\n",
    "    W_parameters = input_size * hidden_size + hidden_size * hidden_size + hidden_size * output_size \n",
    "    b_parameters = hidden_size + hidden_size + output_size\n",
    "    print(f\"Theoretical number of parameters:{W_parameters + b_parameters}\")\n",
    "    sequential2d_net = Sequential2D(in_features_list, out_features_list, blocks)    \n",
    "    return sequential_net, sequential2d_net\n",
    "\n",
    "# Create equivalent networks\n",
    "seq_net, seq2d_net = create_equivalent_networks()\n",
    "\n",
    "print(\"Network architectures created successfully!\")\n",
    "print(f\"Sequential parameters: {sum(p.numel() for p in seq_net.parameters())}\")\n",
    "print(f\"Sequential2D parameters: {sum(p.numel() for p in seq2d_net.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc52be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum difference between outputs: 0.00e+00\n",
      "Outputs are identical\n"
     ]
    }
   ],
   "source": [
    "def test_equivalence():\n",
    "    \"\"\"\n",
    "    Test that both networks produce identical outputs\n",
    "    \"\"\"\n",
    "    # Create test input\n",
    "    batch_size = 32\n",
    "    input_size = 784\n",
    "    test_input = torch.randn(batch_size, input_size)\n",
    "    \n",
    "    # Get outputs from both networks\n",
    "    with torch.no_grad():\n",
    "        # Sequential network forward pass\n",
    "        seq_output = seq_net(test_input)\n",
    "        \n",
    "        seq2d_output = [test_input, None, None, None]\n",
    "\n",
    "        # Here is the magic! You iterate a *fixed* function (seq2d_net) on the input x.  Though the magic of linear\n",
    "        # algebra, this is equivalent to the sequential network.\n",
    "        for i in range(3):\n",
    "            seq2d_output = seq2d_net(seq2d_output)\n",
    "    # Check if outputs are identical.\n",
    "    # Note: the \"output\" of the Sequential2D is a list, where the last element is the output for this particular structure.\n",
    "    max_diff = torch.max(torch.abs(seq_output - seq2d_output[3])).item()\n",
    "    \n",
    "    print(f\"Maximum difference between outputs: {max_diff:.2e}\")\n",
    "    print(f\"Outputs are {'identical' if max_diff < 1e-6 else 'different'}\")\n",
    "    \n",
    "    return seq_output, seq2d_output\n",
    "\n",
    "seq_output, seq2d_output = test_equivalence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10e4d4",
   "metadata": {},
   "source": [
    "## Part 2: Training comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf34469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL in equivalence test for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff06a1",
   "metadata": {},
   "source": [
    "## Part 3: Unique Capabilities of Sequential2D\n",
    "\n",
    "Now let's explore scenarios where Sequential2D offers capabilities that standard Sequential cannot provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc2686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Sequential2D Network Architecture:\n",
      "- Multiple parallel paths from input to output\n",
      "- Skip connections across multiple layers\n",
      "- Aggregation of features at different scales\n",
      "- Total parameters: 85330\n"
     ]
    }
   ],
   "source": [
    "def create_complex_sequential2d():\n",
    "    \"\"\"\n",
    "    Create a Sequential2D network with complex connectivity patterns\n",
    "    that cannot be represented by standard Sequential\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a complex connectivity pattern\n",
    "    cfg = { 'in_features_list': [50, 100, 200, 150],\n",
    "            'out_features_list': [100, 200, 150, 10],\n",
    "            'block_types': [\n",
    "                ['Linear', 'Linear', None,     None],\n",
    "                [None,     'Linear', 'Linear', 'Linear'],\n",
    "                [None,     None,     'Linear', 'Linear'],\n",
    "                [None,     None,     None,     'Linear']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    complex_net = Sequential2D.from_config(cfg)\n",
    "    \n",
    "    print(\"Complex Sequential2D Network Architecture:\")\n",
    "    print(\"- Multiple parallel paths from input to output\")\n",
    "    print(\"- Skip connections across multiple layers\") \n",
    "    print(\"- Aggregation of features at different scales\")\n",
    "    print(f\"- Total parameters: {sum(p.numel() for p in complex_net.parameters())}\")\n",
    "    \n",
    "    return complex_net\n",
    "\n",
    "complex_net = create_complex_sequential2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53962ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 500])\n",
      "Output shape: torch.Size([16, 460])\n",
      "\n",
      "List-based forward pass:\n",
      "Output 0 shape: torch.Size([16, 100])\n",
      "Output 1 shape: torch.Size([16, 200])\n",
      "Output 2: None\n",
      "Output 3: None\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_complex_forward():\n",
    "    \"\"\"\n",
    "    Demonstrate the complex forward pass of Sequential2D\n",
    "    \"\"\"\n",
    "    batch_size = 16\n",
    "    test_input = torch.randn(batch_size, 50+100+200+150)\n",
    "    \n",
    "    # Forward pass through complex network\n",
    "    output = complex_net(test_input)\n",
    "    \n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    \n",
    "    # Let's also try the list-based forward pass\n",
    "    input_list = [torch.randn(batch_size, 50), None, None, None]  # Only provide input to first path\n",
    "    output_list = complex_net.forward_list(input_list)\n",
    "    \n",
    "    print(f\"\\nList-based forward pass:\")\n",
    "    for i, out in enumerate(output_list):\n",
    "        if out is not None:\n",
    "            print(f\"Output {i} shape: {out.shape}\")\n",
    "        else:\n",
    "            print(f\"Output {i}: None\")\n",
    "    \n",
    "    return output, output_list\n",
    "\n",
    "output, output_list = demonstrate_complex_forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterativennsimple-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
